{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = ctypes.CDLL(\"/home/rpiControl/combiExperiments/code/lightLogger/raspberry_pi_firmware/utility/parse_chunk_binary.so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chunk_struct(ctypes.Structure):\n",
    "    _fields_ = [\n",
    "        (\"M\", ctypes.POINTER(ctypes.c_uint8)),\n",
    "        (\"W\", ctypes.POINTER(ctypes.c_uint8)),\n",
    "        (\"P\", ctypes.POINTER(ctypes.c_uint8)),\n",
    "        (\"S\", ctypes.POINTER(ctypes.c_uint8)),\n",
    "        (\"M_size\",ctypes.c_uint8),\n",
    "        (\"W_size\", ctypes.c_uint8),\n",
    "        (\"P_size\", ctypes.c_uint8),\n",
    "        (\"S_size\", ctypes.c_uint8),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define argument and return type for parse_chunk_binary\n",
    "lib.parse_chunk_binary.argtypes = [ctypes.c_char_p]\n",
    "lib.parse_chunk_binary.restype = chunk_struct\n",
    "\n",
    "# Define the argument type for free_chunk_struct\n",
    "lib.free_chunk_struct.argtypes = [ctypes.POINTER(chunk_struct)]\n",
    "lib.free_chunk_struct.restype = None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_chunk_binary(path: str):\n",
    "    # Convert the Python string path to a chunk binary file\n",
    "    # into a bytes object (C-compatible string)\n",
    "    c_path: bytes = path.encode('utf-8')\n",
    "\n",
    "    # Deserialize the chunk using CPP\n",
    "    print(f'Parsing: {c_path}')\n",
    "    chunk: chunk_struct = lib.parse_chunk_binary(c_path)\n",
    "    chunk_dict = dict()\n",
    "    \n",
    "    print(dict(chunk))\n",
    "\n",
    "\n",
    "\n",
    "    # Let's splice out the sensor names and their buffers, as well \n",
    "    # as the length of each buffer\n",
    "    buffer_names_and_values: list = [(name, buffer) \n",
    "                                     for name, buffer in vars(chunk).items()\n",
    "                                     if 'size' not in name]\n",
    "\n",
    "    buffer_sizes: list = [int(field) \n",
    "                          for field in vars(chunk).keys() \n",
    "                          if 'size' in field]\n",
    "\n",
    "\n",
    "\n",
    "    # Now let's iterate over the buffers and read them into numpy arrays\n",
    "    for (name, buffer), size in zip(buffer_names_and_values, buffer_sizes):\n",
    "        print(f'Reshaping: {name} of size: {size}')\n",
    "\n",
    "\n",
    "        # We know the FPS and size of the data, what we don't know \n",
    "        # is how many datapoints are in this buffer, so let's calculate that \n",
    "        #num_readings: int = length_of_buffer / (np.prod(DATA_DIMS) * FPS)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Convert the raw pointers to NumPy arrays\n",
    "    #def pointer_to_numpy(pointer, length):\n",
    "    #    if not pointer:\n",
    "    #        return None\n",
    "    #    return np.ctypeslib.as_array(pointer, shape=(length,))\n",
    "    \n",
    "    # You need to know the lengths of each array in advance\n",
    "    # Adjust these sizes based on your specific application\n",
    "    #m_length = 100  # Example size for M array\n",
    "    #w_length = 100  # Example size for W array\n",
    "    #p_length = 100  # Example size for P array\n",
    "    #s_length = 100  # Example size for S array\n",
    "    \n",
    "    #m_data = pointer_to_numpy(chunk.M, m_length)\n",
    "    #w_data = pointer_to_numpy(chunk.W, w_length)\n",
    "    #p_data = pointer_to_numpy(chunk.P, p_length)\n",
    "    #s_data = pointer_to_numpy(chunk.S, s_length)\n",
    "    \n",
    "    # Free the memory allocated for the buffers in C++\n",
    "    lib.free_chunk_struct(chunk)\n",
    "    \n",
    "    \n",
    "    # Return the data as Python-compatible objects\n",
    "    \n",
    "    return \n",
    "    \n",
    "    return {\n",
    "        \"M\": m_data,\n",
    "        \"W\": w_data,\n",
    "        \"P\": p_data,\n",
    "        \"S\": s_data,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: b'/media/rpiControl/FF5E-7541/test_cpp/chunk_1.bin'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "parse_chunk_binary(path=\"/media/rpiControl/FF5E-7541/test_cpp/chunk_1.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
